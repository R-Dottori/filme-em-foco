{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projeto de Bloco: Ciência de Dados Aplicada**\n",
    "# **Teste de Performance 2 (TP2)**\n",
    "## Instituto Infnet - Rafael Dottori de Oliveira\n",
    "\n",
    "### 23/09/2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enunciado\n",
    "\n",
    "*Na primeira etapa do projeto, você fez a proposta da aplicação, organizou o planejamento inicial e configurou os aspectos básicos do projeto, incluindo a criação de uma aplicação demo em Streamlit.*\n",
    "\n",
    "*Com isso, você estabeleceu as bases para a solução tecnológica para resolver algum problema ligado aos ODS da Agenda 2030.*\n",
    "\n",
    "*Agora, é hora de dar um passo adiante e evoluir a sua aplicação, implementando funcionalidades mais avançadas que proporcionarão maior interatividade, usabilidade e eficiência.*\n",
    "\n",
    "*O TP2 focará na ampliação das capacidades técnicas e na integração de novas funcionalidades, permitindo que sua aplicação não apenas visualize dados, mas também interaja de maneira dinâmica com os usuários e processe informações de fontes externas.*\n",
    "\n",
    "> *Objetivo:*\n",
    "\n",
    "*No segundo TP do projeto, você terá a oportunidade de aprimorar e evoluir a aplicação desenvolvida na fase anterior.*\n",
    "\n",
    "*Nesta etapa, o foco será na configuração do ambiente de desenvolvimento, na implementação de uma interface de usuário mais interativa e na integração de novas funcionalidades para melhorar a experiência do usuário e a performance da aplicação.*\n",
    "\n",
    "> *Entrega:*\n",
    "\n",
    "*Ao final desta etapa, sua aplicação deverá estar significativamente mais avançada, com uma interface de usuário interativa e funcional, capacidade de extrair e processar dados de fontes externas, e melhor performance graças ao uso de cache e estado de sessão.*\n",
    "\n",
    "*Além disso, a documentação do projeto, incluindo o Project Charter e o Data Summary Report, deverá estar completa e refletir o progresso feito até o momento.*\n",
    "\n",
    "> *Dicas:*\n",
    "\n",
    "*Lembre-se de testar todas as funcionalidades implementadas para garantir que a aplicação esteja funcionando corretamente.*\n",
    "\n",
    "*Utilize o controle de versão com Git para documentar e organizar as mudanças no código.*\n",
    "\n",
    "*Use uma plataforma como Github para armazenar o repositório.*\n",
    "\n",
    "*Mantenha a organização dos diretórios e arquivos, seguindo as melhores práticas de desenvolvimento.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exercício 1 - Configuração do Ambiente de Desenvolvimento**\n",
    "\n",
    "*Configure seu ambiente de desenvolvimento, incluindo Git para controle de versão e preparação para deploy. Lembre-se de seguir a estrutura do CRISP-DM para organizar seu projeto de forma eficiente e escalável.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• **Ambiente Virtual e Instalações**\n",
    "\n",
    "Iremos reaproveitar o ambiente virtual do TP1, mas poderíamos criar um novo usando o seguinte comando no terminal, certificando que estamos no diretório desejado:\n",
    "\n",
    "> python -m venv .venv_app\n",
    "\n",
    "Onde \".venv_app\" é o nome do nosso ambiente. Em seguida, ativamos o ambiente, também via terminal:\n",
    "\n",
    "> .venv_app/Scripts/activate\n",
    "\n",
    "Criamos um arquivo \"requirements.txt\" com as bibliotecas que desejamos instalar, como o pandas, streamlit e jupyter. Para realizar essas instalações no ambiente virtual ativado, digitamos:\n",
    "\n",
    "> python -m pip install -r requirements.txt\n",
    "\n",
    "• **Git**\n",
    "\n",
    "Feita a configuração local, podemos criar um novo projeto no GitHub pelo próprio Visual Studio Code.\n",
    "\n",
    "No menu lateral, temos a aba de Source Control onde podemos publicar o projeto no GitHub, selecionando quais arquivos locais queremos subir para o repositório, como na imagem abaixo:\n",
    "\n",
    "![create_git](./docs/git_create_project.png)\n",
    "\n",
    "Uma funcionalidade importante do Git é o *commit* — onde publicamos as mudanças realizadas nos arquivos, por exemplo no arquivo do aplicativo Streamlit. É possível verificar todas as linhas com alterações e subir essas mudanças para o repositório no GitHub.\n",
    "\n",
    "![commit_changes_git](./docs/git_commit_changes.png)\n",
    "\n",
    "Além disso, podemos testar alterações em diferentes ramificações (*branches*) do projeto, podemos importar para nossa máquina mudanças feitas por outros contribuidores com o *pull*, baixar versões anteriores, etc.\n",
    "\n",
    "Essas operações do Git nos permitem controlar a progressão do projeto, acessar diferentes etapas da modelagem, sincronizar o trabalho de uma equipe com diversas pessoas.\n",
    "\n",
    "• **CRISP-DM**\n",
    "\n",
    "O controle de versionamento citado acima também está ligado as fases do CRISP-DM ou TDSP, já que essas metodologias podem ser pensadas de maneira cíclica. Ou seja, é possível retomar diferentes etapas do projeto de acordo com nossas necessidades.\n",
    "\n",
    "Por exemplo, durante a etapa de modelagem ou implementação, talvez seja preciso reavaliar o entendimento de negócio ou dos dados. Podemos então aplicar uma nova abordagem de modelagem em um *branch* diferente. Ou podemos dar continuidade a uma funcionalidade que estava no começo do trabalho mas havia sido deixada de lado.\n",
    "\n",
    "• **GitHub:** https://github.com/R-Dottori/filme-em-foco\n",
    "\n",
    "• **Streamlit**: https://filme-em-foco-tp2.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercício 2 - Implementação de Interface de Usuário Dinâmica**\n",
    "\n",
    "*Evolua a interface inicial da sua aplicação Streamlit, acrescentando elementos de interatividade que permitam ações dinâmicas por parte do usuário. A interface deve ser intuitiva e funcional, garantindo uma boa experiência de uso.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao longo do trabalho, iremos fazer recortes do aplicativo final (que está no último item desse *notebook*) para **destacar o código e as funcionalidades exigidas em cada exercício**.\n",
    "\n",
    "Aqui, subimos diretamente a base dos complexos obtidos via a API do Ingresso.com (o processo inteiro está no *notebook* em ./modeling/api_query.ipynb) e permitimos ao usuário filtrar os cinemas por bairro.\n",
    "\n",
    "Além disso, uma versão inicial do mapa interativo que divide o município do Rio de Janeiro por suas Regiões Administrativas e exibe a localização dos complexos citados acima (esses códigos também estão em ./modeling/folium_map.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/tp2_ex2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/tp2_ex2.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from streamlit_folium import st_folium\n",
    "\n",
    "st.title('Interface de Usuário')\n",
    "\n",
    "st.header('Complexos de Cinema no Rio de Janeiro')\n",
    "salas_rj = pd.read_csv('./data/salas_rj.csv', index_col=0)\n",
    "bairros = sorted(salas_rj['neighborhood'].unique())\n",
    "filtro = st.multiselect(label='Selecione quais bairros deseja exibir:', options=bairros, default=bairros)\n",
    "st.write(salas_rj[['name', 'neighborhood']][salas_rj['neighborhood'].isin(filtro)].sort_values('neighborhood'))\n",
    "\n",
    "st.header('Mapa dos Complexos por Região Administrativa')\n",
    "shapefile_rj = gpd.read_file('./data/Regioes Administrativas - RAs - PCRJ.zip')\n",
    "lat = -22.92\n",
    "lon = -43.47\n",
    "mapa_rj = folium.Map(location=[lat, lon], zoom_start=10)\n",
    "folium.GeoJson(shapefile_rj.to_json(), name='Regiões Administrativas',\n",
    "                   style_function=lambda feature: {\n",
    "        'fillColor': '#24b1f2',\n",
    "        'color': 'black',\n",
    "        'weight': 2,\n",
    "        'dashArray': '5, 5',\n",
    "        'fillOpacity': 0.5,\n",
    "    }\n",
    ").add_to(mapa_rj)\n",
    "\n",
    "for idx, sala in salas_rj.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[sala['latitude'], sala['longitude']],\n",
    "        tooltip=sala['name'],\n",
    "        icon=folium.Icon(color='white')\n",
    "    ).add_to(mapa_rj)\n",
    "\n",
    "folium.LayerControl().add_to(mapa_rj)\n",
    "st_folium(mapa_rj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercício 3 - Extração de Conteúdo da Web para alimentar a aplicação**\n",
    "\n",
    "*Utilize a ferramenta Beautiful Soup para extrair conteúdo de páginas web. Execute esses códigos separadamente e armazene os dados obtidos em arquivos CSV e/ou TXT nos diretórios de data/.\n",
    "Posteriormente, utilize esses dados para alimentar a interface da aplicação: exiba informações relevantes geradas a partir do conteúdo obtido, como nuvens de palavras e estatísticas básicas (tabelas, notícias).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exercício usamos os filtros para não só selecionar um bairro do Rio de Janeiro como escolher um complexo específico.\n",
    "\n",
    "Depois, mostramos quais os filmes estão em cartaz atualmente no cinema escolhido (com uma nova consulta a API).\n",
    "\n",
    "Então, com o filme selecionado, fazemos uma raspagem de dados no portal IMDb, retirando o título, nome do diretor e as análises dos usuários.\n",
    "\n",
    "Com as análises, montamos uma nuvem de palavras destacando os termos mais comuns.\n",
    "\n",
    "(A etapa de raspagem de dados está em ./modeling/web_scraping.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/tp2_ex3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/tp2_ex3.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Carregando Dados Básicos\n",
    "salas_rj = pd.read_csv('./data/salas_rj.csv', index_col=0)\n",
    "UA = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "raiz_api = 'https://api-content.ingresso.com/v0/Sessions/city/2/theater/{}'\n",
    "filme_escolhido = ''\n",
    "\n",
    "\n",
    "# Título do Exercício 3\n",
    "st.title('Raspagem de Dados')\n",
    "\n",
    "# Escolha do bairro e complexo de cinema\n",
    "st.header('Escolha um bairro e um cinema:')\n",
    "\n",
    "bairros = sorted(salas_rj['neighborhood'].unique())\n",
    "filtro_bairro = st.selectbox(label='Selecione um bairro:', options=bairros)\n",
    "salas_bairro = salas_rj[salas_rj['neighborhood'] == filtro_bairro]['name'].unique()\n",
    "\n",
    "filtro_cinema = st.selectbox(label='Selecione um complexo de cinema:', options=salas_bairro)\n",
    "id_cinema = salas_rj[salas_rj['name'] == filtro_cinema]['id'].values[0]\n",
    "\n",
    "\n",
    "# Resgatando os filmes em cartaz do complexo escolhido\n",
    "st.header('Escolha um filme:')\n",
    "\n",
    "try:\n",
    "    resp = requests.get(\n",
    "        url=raiz_api.format(id_cinema),\n",
    "        headers={'user-agent': UA}\n",
    "        )\n",
    "\n",
    "    dados_complexo = resp.json()\n",
    "    filmes_complexo = []\n",
    "\n",
    "    for dia in dados_complexo:\n",
    "        for filme in dia['movies']:\n",
    "            filmes_complexo.append(filme)\n",
    "\n",
    "    filmes_cartaz = pd.DataFrame(filmes_complexo)\n",
    "    st.write(filmes_cartaz[['title', 'originalTitle']].drop_duplicates().sort_values('title'))\n",
    "    filme_escolhido = st.selectbox(label='Selecione um filme:', options=sorted(filmes_cartaz['title'].drop_duplicates()))\n",
    "except:\n",
    "    st.error('ERRO! Não encontramos sessões para o complexo escolhido. Por favor, selecione outro cinema.')\n",
    "\n",
    "# Após escolher um filme, faremos operações de raspagem no portal IMDb\n",
    "if filme_escolhido != '':\n",
    "    st.header('IMDb')\n",
    "\n",
    "    # Selecionando o primeiro resultado da busca, e esperando que seja igual ao filme escolhido\n",
    "    url_busca = f'https://www.imdb.com/find/?q={filme_escolhido}&ref_=nv_sr_sm'\n",
    "    resp_imdb = requests.get(\n",
    "        url=url_busca,\n",
    "        headers={'user-agent': UA}\n",
    "        )\n",
    "    soup_busca = bs(resp_imdb.text)\n",
    "\n",
    "    # Raspando a página do primeiro resultado da busca\n",
    "    url_filme = 'https://www.imdb.com/' + soup_busca.select('ul > li > div > div > a')[0]['href']\n",
    "    resp_filme = requests.get(\n",
    "        url=url_filme,\n",
    "        headers={'user-agent': UA}\n",
    "    )\n",
    "    soup_filme = bs(resp_filme.text)\n",
    "\n",
    "    titulo_filme = soup_filme.select('h1 > span')[0].text\n",
    "    diretor_filme = soup_filme.select('ul > li > div > ul > li > a')[0].text\n",
    "\n",
    "    # Entrando nas análises dos usuários pro filme e raspando os textos\n",
    "    url_analises = 'https://www.imdb.com/' + soup_filme.select('section[data-testid=\"UserReviews\"] > div > div > a')[0]['href']\n",
    "    resp_analises = requests.get(\n",
    "                    url=url_analises,\n",
    "                    headers={'user-agent': UA}\n",
    "                )   \n",
    "    soup_analises = bs(resp_analises.text)\n",
    "    analises = ''\n",
    "    for tag in soup_analises.select('div[class=\"lister-list\"]'):\n",
    "        for analise in tag.select('div[class=\"text show-more__control\"]'):\n",
    "            analises += (analise.text.replace('\\n', '').replace(\"'\", \"\")) + ' '\n",
    "\n",
    "    # Exibindo um pouco da raspagem, o que também confirma se o primeiro resultado da busca estava correto\n",
    "    st.subheader('Informações do Filme:')\n",
    "    st.write(f'Título: {titulo_filme}')\n",
    "    st.write(f'Diretor: {diretor_filme}')\n",
    "\n",
    "    # Nuvem de Palavras com as análises\n",
    "    st.subheader('Nuvem de Palavras')\n",
    "    nuvem = WordCloud().generate(analises)\n",
    "    plt.figure()\n",
    "    plt.imshow(nuvem)\n",
    "    plt.axis('off')\n",
    "    st.pyplot(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercício 4: Cache e Estado de Sessão**\n",
    "\n",
    "*Implemente cache e estado de sessão em Streamlit para melhorar a performance da aplicação e garantir a persistência dos dados em aplicações interativas. Isso permitirá que os dados sejam mantidos ao longo das interações do usuário, proporcionando uma experiência mais fluida*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui começamos a explorar um aplicativo com páginas diferentes para testar a persistência dos dados entre diferentes seções do aplicativo.\n",
    "\n",
    "Também implementos funcionalidades de cache, para garantir o carregamento mais rápido de bases que já foram usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/tp2_ex4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/tp2_ex4.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "pag_1_title = 'Página 1 - Carregando os Dados'\n",
    "pag_2_title = 'Página 2 - Exibindo os Dados'\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def subir_base(arquivo):\n",
    "    df = pd.read_csv(arquivo, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pagina_um():\n",
    "    if 'df' not in st.session_state:\n",
    "        st.session_state['df'] = None\n",
    "    \n",
    "    st.title('Cache e Estado de Sessão')\n",
    "    st.header(pag_1_title)\n",
    "\n",
    "    arquivo = st.file_uploader('Insira um arquivo CSV:', type='csv')\n",
    "    if arquivo is not None:\n",
    "        with st.spinner('Carregando...'):\n",
    "            st.session_state['df'] = subir_base(arquivo)\n",
    "            st.success('Base carregada com sucesso.')\n",
    "\n",
    "\n",
    "def pagina_dois():\n",
    "    st.header(pag_2_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        st.write(st.session_state['df'])\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "st.sidebar.title('Navegação')\n",
    "pagina = st.sidebar.radio(label='Escolha uma página:', options=(pag_1_title, pag_2_title))\n",
    "if pagina == pag_1_title:\n",
    "    pagina_um()\n",
    "else:\n",
    "    pagina_dois()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercício 5: Serviço de Upload e Download de Arquivos**\n",
    "\n",
    "*Desenvolva um serviço de upload e download de arquivos em Streamlit, permitindo que o usuário adicione mais informações ao sistema através de arquivos CSV. Esses dados devem complementar as informações já exibidas na aplicação, tornando-a mais robusta e informativa.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exercício, continuamos a estrutura de várias páginas e permitimos aos usuários subirem dados de novos complexos de cinema.\n",
    "\n",
    "Utilizamos dois complexos fictícios (./data/salas_rj_adicionar.csv) que propõem a criação de cinemas em Regiões Administrativas que não tinham nenhuma sala, ambos na Zona Oeste do Rio de Janeiro.\n",
    "\n",
    "É possível baixar a nova tabela gerada, e o mapa interativo exibe os novos complexos com um marcador diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/tp2_ex5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/tp2_ex5.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from streamlit_folium import st_folium\n",
    "\n",
    "app_title = 'Subir e Baixar Arquivos'\n",
    "pag_1_title = 'Carregar os Dados'\n",
    "pag_2_title = 'Exibir Tabela'\n",
    "pag_3_title = 'Mapa'\n",
    "pag_4_title = 'Adicionar Complexos'\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def subir_base(arquivo):\n",
    "    df = pd.read_csv(arquivo, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pagina_um():\n",
    "    if 'df' not in st.session_state:\n",
    "        st.session_state['df'] = None\n",
    "\n",
    "    if 'novo_df' not in st.session_state:\n",
    "        st.session_state['novo_df'] = None\n",
    "    \n",
    "    st.title(app_title)\n",
    "    st.header(pag_1_title)\n",
    "\n",
    "    arquivo = st.file_uploader('Insira um arquivo CSV:', type='csv')\n",
    "    if arquivo is not None:\n",
    "        with st.spinner('Carregando...'):\n",
    "            st.session_state['df'] = subir_base(arquivo)\n",
    "            st.success('Base carregada com sucesso.')\n",
    "\n",
    "\n",
    "def pagina_dois():\n",
    "    st.header(pag_2_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        st.write(st.session_state['df'])\n",
    "        if st.session_state['novo_df'] is not None:\n",
    "            st.header('Baixar base com os novos dados:')\n",
    "            df_download = st.session_state['df'].to_csv()\n",
    "            st.download_button(\n",
    "                label='Baixar',\n",
    "                data=df_download,\n",
    "                file_name='salas_rj_atualizado.csv'\n",
    "                )\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "def pagina_tres():\n",
    "    st.header(pag_3_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        shapefile_rj = gpd.read_file('./data/Regioes Administrativas - RAs - PCRJ.zip')\n",
    "        lat = -22.92\n",
    "        lon = -43.47\n",
    "        mapa_rj = folium.Map(location=[lat, lon], zoom_start=10)\n",
    "        folium.GeoJson(shapefile_rj.to_json(), name='Regiões Administrativas',\n",
    "                        style_function=lambda feature: {\n",
    "                'fillColor': '#24b1f2',\n",
    "                'color': 'black',\n",
    "                'weight': 2,\n",
    "                'dashArray': '5, 5',\n",
    "                'fillOpacity': 0.5,\n",
    "            }\n",
    "        ).add_to(mapa_rj)\n",
    "\n",
    "        for idx, sala in st.session_state['df'].iterrows():\n",
    "            if idx <= 40:\n",
    "                folium.Marker(\n",
    "                    location=[sala['latitude'], sala['longitude']],\n",
    "                    tooltip=sala['name'],\n",
    "                    icon=folium.Icon(color='white')\n",
    "                ).add_to(mapa_rj)\n",
    "            else:\n",
    "                folium.Marker(\n",
    "                    location=[sala['latitude'], sala['longitude']],\n",
    "                    tooltip=sala['name'],\n",
    "                    icon=folium.Icon(icon='glyphicon glyphicon-film', color='red')\n",
    "                ).add_to(mapa_rj)\n",
    "\n",
    "        folium.LayerControl().add_to(mapa_rj)\n",
    "        st_folium(mapa_rj)\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "def pagina_quatro():\n",
    "    st.header(pag_4_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        dados_exemplo = {'id': '1234', 'name': 'Nome do Complexo', 'neighborhood': 'Bairro', 'latitude': -22.92, 'longitude': -43.47}\n",
    "        df_exemplo = pd.DataFrame(dados_exemplo, index=[0])\n",
    "        st.write('Para adicionar novos dados, insira um arquivo CSV respeitando o seguinte esquema:')\n",
    "        st.write(df_exemplo)\n",
    "\n",
    "        novo_arquivo = st.file_uploader('Insira o arquivo CSV:', type='csv')\n",
    "        if novo_arquivo is not None:\n",
    "            with st.spinner('Carregando...'):\n",
    "                st.session_state['novo_df'] = subir_base(novo_arquivo)\n",
    "            if set(st.session_state['df'].columns) == set(st.session_state['novo_df'].columns):\n",
    "                st.write(st.session_state['novo_df'])\n",
    "                st.session_state['df'] = pd.concat([st.session_state['df'], st.session_state['novo_df']], ignore_index=True)\n",
    "                st.success('Novos dados adicionados com sucesso.')\n",
    "                st.header('Baixar base com os novos dados:')\n",
    "                df_download = st.session_state['df'].to_csv()\n",
    "                st.download_button(\n",
    "                    label='Baixar',\n",
    "                    data=df_download,\n",
    "                    file_name='salas_rj_atualizado.csv'\n",
    "                    )\n",
    "            else:\n",
    "                st.error('ERRO! Os dados inseridos não seguem o esquema exigido.')\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "st.sidebar.title('Navegação')\n",
    "pagina = st.sidebar.radio(label='Escolha uma página:', options=(pag_1_title, pag_2_title, pag_3_title, pag_4_title))\n",
    "if pagina == pag_1_title:\n",
    "    pagina_um()\n",
    "elif pagina == pag_2_title:\n",
    "    pagina_dois()\n",
    "elif pagina == pag_3_title:\n",
    "    pagina_tres()\n",
    "else:\n",
    "    pagina_quatro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercício 6: Finalização do Project Charter e Data Summary Report**\n",
    "\n",
    "*Complete o Project Charter e o Data Summary Report, detalhando o escopo, os objetivos, os stakeholders do projeto, e as fontes de dados utilizadas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Project Charter - Business Model Canvas**\n",
    "\n",
    "![folders](docs/business_model_canvas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Summary Report**\n",
    "\n",
    "• API do Ingresso.com:\n",
    "\n",
    "— Fonte: Consultas na API do Ingresso.com\n",
    "\n",
    "— Formato: Dados textuais em tabelas .CSV\n",
    "\n",
    "— Objetivo: Catálogo dos complexos de cinema no município do Rio de Janeiro, utilizando uma fonte via API.\n",
    "\n",
    "— — — \n",
    "\n",
    "• Shapefile com os polígonos das Regiões Administrativas do Rio de Janeiro:\n",
    "\n",
    "— Fonte: Disponibilizado pelo Sistema Municipal de Informações Urbanas- SIURB/PCRJ\n",
    "\n",
    "— Formato: Arquivo .zip contendo o Shapefile (incluindo outros arquivos .shp, .dbf, .shx, etc.)\n",
    "\n",
    "— Objetivo: Criar um mapa interativo com as divisões de RAs e mapear cada complexo de cinema de acordo\n",
    "\n",
    "— — —\n",
    "\n",
    "• Informações do IMDb:\n",
    "\n",
    "— Fonte: Raspagem de dados de filmes no portal IMDb\n",
    "\n",
    "— Formato: Dados textuais contendo informações como título do filme, diretor e análises dos usuários\n",
    "\n",
    "— Objetivo: Exibir informações dos filmes que não estão disponíveis na API e criar nuvem de palavras com os termos mais usados pelos espectadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Aplicativo**\n",
    "\n",
    "Finalmente temos o **aplicativo final do TP2**, incluindo todas as funcionalidades exigidas nos exercícios.\n",
    "\n",
    "**GitHub:** https://github.com/R-Dottori/filme-em-foco\n",
    "\n",
    "**Streamlit**: https://filme-em-foco-tp2.streamlit.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./apps/tp2_app_final.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./apps/tp2_app_final.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from streamlit_folium import st_folium\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "app_title = 'Subir e Baixar Arquivos'\n",
    "pag_1_title = 'Carregar os Dados'\n",
    "pag_2_title = 'Exibir Tabela'\n",
    "pag_3_title = 'Mapa'\n",
    "pag_4_title = 'Adicionar Complexos'\n",
    "pag_5_title = 'Escolher um Filme'\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def subir_base(arquivo):\n",
    "    df = pd.read_csv(arquivo, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pagina_um():\n",
    "    if 'df' not in st.session_state:\n",
    "        st.session_state['df'] = None\n",
    "\n",
    "    if 'novo_df' not in st.session_state:\n",
    "        st.session_state['novo_df'] = None\n",
    "    \n",
    "    st.title(app_title)\n",
    "    st.header(pag_1_title)\n",
    "\n",
    "    arquivo = st.file_uploader('Insira um arquivo CSV:', type='csv')\n",
    "    if arquivo is not None:\n",
    "        with st.spinner('Carregando...'):\n",
    "            st.session_state['df'] = subir_base(arquivo)\n",
    "            st.success('Base carregada com sucesso.')\n",
    "\n",
    "\n",
    "def pagina_dois():\n",
    "    st.header(pag_2_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        st.write(st.session_state['df'])\n",
    "        if st.session_state['novo_df'] is not None:\n",
    "            st.header('Baixar base com os novos dados:')\n",
    "            df_download = st.session_state['df'].to_csv()\n",
    "            st.download_button(\n",
    "                label='Baixar',\n",
    "                data=df_download,\n",
    "                file_name='salas_rj_atualizado.csv'\n",
    "                )\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "def pagina_tres():\n",
    "    st.header(pag_3_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        shapefile_rj = gpd.read_file('./data/Regioes Administrativas - RAs - PCRJ.zip')\n",
    "        lat = -22.92\n",
    "        lon = -43.47\n",
    "        mapa_rj = folium.Map(location=[lat, lon], zoom_start=10)\n",
    "        folium.GeoJson(shapefile_rj.to_json(), name='Regiões Administrativas',\n",
    "                        style_function=lambda feature: {\n",
    "                'fillColor': '#24b1f2',\n",
    "                'color': 'black',\n",
    "                'weight': 2,\n",
    "                'dashArray': '5, 5',\n",
    "                'fillOpacity': 0.5,\n",
    "            }\n",
    "        ).add_to(mapa_rj)\n",
    "\n",
    "        for idx, sala in st.session_state['df'].iterrows():\n",
    "            if idx <= 40:\n",
    "                folium.Marker(\n",
    "                    location=[sala['latitude'], sala['longitude']],\n",
    "                    tooltip=sala['name'],\n",
    "                    icon=folium.Icon(color='white')\n",
    "                ).add_to(mapa_rj)\n",
    "            else:\n",
    "                folium.Marker(\n",
    "                    location=[sala['latitude'], sala['longitude']],\n",
    "                    tooltip=sala['name'],\n",
    "                    icon=folium.Icon(icon='glyphicon glyphicon-film', color='red')\n",
    "                ).add_to(mapa_rj)\n",
    "\n",
    "        folium.LayerControl().add_to(mapa_rj)\n",
    "        st_folium(mapa_rj)\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "def pagina_quatro():\n",
    "    st.header(pag_4_title)\n",
    "    if st.session_state['df'] is not None:\n",
    "        dados_exemplo = {'id': '1234', 'name': 'Nome do Complexo', 'neighborhood': 'Bairro', 'latitude': -22.92, 'longitude': -43.47}\n",
    "        df_exemplo = pd.DataFrame(dados_exemplo, index=[0])\n",
    "        st.write('Para adicionar novos dados, insira um arquivo CSV respeitando o seguinte esquema:')\n",
    "        st.write(df_exemplo)\n",
    "\n",
    "        novo_arquivo = st.file_uploader('Insira o arquivo CSV:', type='csv')\n",
    "        if novo_arquivo is not None:\n",
    "            with st.spinner('Carregando...'):\n",
    "                st.session_state['novo_df'] = subir_base(novo_arquivo)\n",
    "            if set(st.session_state['df'].columns) == set(st.session_state['novo_df'].columns):\n",
    "                st.write(st.session_state['novo_df'])\n",
    "                st.session_state['df'] = pd.concat([st.session_state['df'], st.session_state['novo_df']], ignore_index=True)\n",
    "                st.success('Novos dados adicionados com sucesso.')\n",
    "                st.header('Baixar base com os novos dados:')\n",
    "                df_download = st.session_state['df'].to_csv()\n",
    "                st.download_button(\n",
    "                    label='Baixar',\n",
    "                    data=df_download,\n",
    "                    file_name='salas_rj_atualizado.csv'\n",
    "                    )\n",
    "            else:\n",
    "                st.error('ERRO! Os dados inseridos não seguem o esquema exigido.')\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "def pagina_cinco():\n",
    "    st.header(pag_5_title)\n",
    "    UA = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "    raiz_api = 'https://api-content.ingresso.com/v0/Sessions/city/2/theater/{}'\n",
    "    filme_escolhido = ''\n",
    "    if st.session_state['df'] is not None:\n",
    "        # Escolha do bairro e complexo de cinema\n",
    "        st.header('Escolha um bairro e um cinema:')\n",
    "\n",
    "        bairros = sorted(st.session_state['df']['neighborhood'].unique())\n",
    "        filtro_bairro = st.selectbox(label='Selecione um bairro:', options=bairros)\n",
    "        salas_bairro = st.session_state['df'][st.session_state['df']['neighborhood'] == filtro_bairro]['name'].unique()\n",
    "\n",
    "        filtro_cinema = st.selectbox(label='Selecione um complexo de cinema:', options=salas_bairro)\n",
    "        id_cinema = st.session_state['df'][st.session_state['df']['name'] == filtro_cinema]['id'].values[0]\n",
    "\n",
    "\n",
    "        # Resgatando os filmes em cartaz do complexo escolhido\n",
    "        st.header('Escolha um filme:')\n",
    "\n",
    "        try:\n",
    "            resp = requests.get(\n",
    "                url=raiz_api.format(id_cinema),\n",
    "                headers={'user-agent': UA}\n",
    "                )\n",
    "\n",
    "            dados_complexo = resp.json()\n",
    "            filmes_complexo = []\n",
    "\n",
    "            for dia in dados_complexo:\n",
    "                for filme in dia['movies']:\n",
    "                    filmes_complexo.append(filme)\n",
    "\n",
    "            filmes_cartaz = pd.DataFrame(filmes_complexo)\n",
    "            st.write(filmes_cartaz[['originalTitle']].drop_duplicates().sort_values('originalTitle'))\n",
    "            filme_escolhido = st.selectbox(label='Selecione um filme:', options=sorted(filmes_cartaz['originalTitle'].drop_duplicates()))\n",
    "        except:\n",
    "            st.error('ERRO! Não encontramos sessões para o complexo escolhido. Por favor, selecione outro cinema.')\n",
    "\n",
    "        # Após escolher um filme, faremos operações de raspagem no portal IMDb\n",
    "        if filme_escolhido != '':\n",
    "            st.header('IMDb')\n",
    "            try:\n",
    "                with st.spinner('Carregando...'):\n",
    "                    # Selecionando o primeiro resultado da busca, e esperando que seja igual ao filme escolhido\n",
    "                    url_busca = f'https://www.imdb.com/find/?q={filme_escolhido}&ref_=nv_sr_sm'\n",
    "                    resp_imdb = requests.get(\n",
    "                        url=url_busca,\n",
    "                        headers={'user-agent': UA}\n",
    "                        )\n",
    "                    soup_busca = bs(resp_imdb.text)\n",
    "\n",
    "                    # Raspando a página do primeiro resultado da busca\n",
    "                    url_filme = 'https://www.imdb.com/' + soup_busca.select('ul > li > div > div > a')[0]['href']\n",
    "                    resp_filme = requests.get(\n",
    "                        url=url_filme,\n",
    "                        headers={'user-agent': UA}\n",
    "                    )\n",
    "                    soup_filme = bs(resp_filme.text)\n",
    "\n",
    "                    titulo_filme = soup_filme.select('h1 > span')[0].text\n",
    "                    diretor_filme = soup_filme.select('ul > li > div > ul > li > a')[0].text\n",
    "\n",
    "                    # Entrando nas análises dos usuários pro filme e raspando os textos\n",
    "                    url_analises = 'https://www.imdb.com/' + soup_filme.select('section[data-testid=\"UserReviews\"] > div > div > a')[0]['href']\n",
    "                    resp_analises = requests.get(\n",
    "                                    url=url_analises,\n",
    "                                    headers={'user-agent': UA}\n",
    "                                )   \n",
    "                    soup_analises = bs(resp_analises.text)\n",
    "                    analises = ''\n",
    "                    for tag in soup_analises.select('div[class=\"lister-list\"]'):\n",
    "                        for analise in tag.select('div[class=\"text show-more__control\"]'):\n",
    "                            analises += (analise.text.replace('\\n', '').replace(\"'\", \"\")) + ' '\n",
    "\n",
    "                    # Exibindo um pouco da raspagem, o que também confirma se o primeiro resultado da busca estava correto\n",
    "                    st.subheader('Informações do Filme:')\n",
    "                    st.write(f'Título: {titulo_filme}')\n",
    "                    st.write(f'Diretor: {diretor_filme}')\n",
    "\n",
    "                    # Nuvem de Palavras com as análises\n",
    "                    st.subheader('Nuvem de Palavras')\n",
    "                    nuvem = WordCloud().generate(analises)\n",
    "                    plt.figure()\n",
    "                    plt.imshow(nuvem)\n",
    "                    plt.axis('off')\n",
    "                    st.pyplot(plt)\n",
    "            except:\n",
    "                st.error('ERRO! Filme não encontrado no IMDb, por favor selecione outro.')\n",
    "    else:\n",
    "        st.warning('Aguardando o carregamento da base.')\n",
    "\n",
    "\n",
    "st.sidebar.title('Navegação')\n",
    "pagina = st.sidebar.radio(label='Escolha uma página:', options=(pag_1_title, pag_2_title, pag_3_title, pag_4_title, pag_5_title))\n",
    "if pagina == pag_1_title:\n",
    "    pagina_um()\n",
    "elif pagina == pag_2_title:\n",
    "    pagina_dois()\n",
    "elif pagina == pag_3_title:\n",
    "    pagina_tres()\n",
    "elif pagina == pag_4_title:\n",
    "    pagina_quatro()\n",
    "else:\n",
    "    pagina_cinco()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
